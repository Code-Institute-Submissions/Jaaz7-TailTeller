{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Model Testing Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* \n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* \n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-08 10:05:27.138648: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-05-08 10:05:27.138826: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-05-08 10:05:27.140684: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-05-08 10:05:27.162059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-08 10:05:27.530243: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/tmp/ipykernel_12277/159174841.py:8: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import gc\n",
        "from keras.models import load_model\n",
        "from tqdm.autonotebook import tqdm\n",
        "from keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "from keras.layers import Input, Lambda, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from keras.applications import InceptionV3, Xception, NASNetLarge, InceptionResNetV2\n",
        "from keras.applications.inception_v3 import preprocess_input as inception_preprocessor\n",
        "from keras.applications.xception import preprocess_input as xception_preprocessor\n",
        "from keras.applications.nasnet import preprocess_input as nasnet_preprocessor\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input as inc_resnet_preprocessor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/jaaz/Desktop/project-5/TailTeller/jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to make the parent of the current directory the new current directory.\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chdir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New current directory: /home/jaaz/Desktop/project-5/TailTeller\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"New current directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Let's load the get_features function again in order to run the dog images in the train/ folder through the models we already know. This folder was untouched until now and will be used from now on to see how our model performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_size = (299,299,3)\n",
        "\n",
        "def get_features(model_name, model_preprocessor, input_size, data):\n",
        "\n",
        "    input_layer = Input(input_size)\n",
        "    preprocessor = Lambda(model_preprocessor)(input_layer)\n",
        "    base_model = model_name(weights='imagenet', include_top=False,\n",
        "                            input_shape=input_size)(preprocessor)\n",
        "    avg = GlobalAveragePooling2D()(base_model)\n",
        "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
        "    \n",
        "    #Extract feature\n",
        "    feature_maps = feature_extractor.predict(data, verbose=1)\n",
        "    print('Feature maps shape: ', feature_maps.shape)\n",
        "    return feature_maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Let's read the images from the test directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a function to load the images in the train/ folder, pre-process them into a numpy array and also return the corresponding ids (breed labels) before extracting the features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_test_images(data_dir, img_size=(299, 299, 3)):\n",
        "    \"\"\"\n",
        "    This function loads and processes images from the test/ directory into a numpy array\n",
        "    Parameters:\n",
        "        test_dir: str, path to the directory containing the test images\n",
        "        img_size: tuple, size to which the images should be resized (width, height, channels)\n",
        "    Returns:\n",
        "        A numpy array containing the processed images\n",
        "        A list of filenames (ids) of the images\n",
        "    \"\"\"\n",
        "    # Making the full file paths for each image in the test directory\n",
        "    test_filenames = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir)]\n",
        "\n",
        "    # Determine the number of images\n",
        "    data_size = len(test_filenames)\n",
        "\n",
        "    #Preallocate a numpy array to hold all images\n",
        "    images = np.zeros((data_size, img_size[0], img_size[1], img_size[2]), dtype=np.uint8)\n",
        "    \n",
        "    #Load each image, resize it and store it in the preallocated array\n",
        "    for ix, img_path in enumerate(tqdm(test_filenames, desc=\"Processing images\")):\n",
        "        img = load_img(img_path, target_size=img_size)\n",
        "        images[ix] = img\n",
        "        # Free RAM\n",
        "        del img\n",
        "    \n",
        "    # Display the final data size\n",
        "    print(f\"Final data size {images.shape}\")\n",
        "\n",
        "    # Extract ids from filenames\n",
        "    ids = [os.path.basename(fname).split('.')[0] for fname in test_filenames]\n",
        "\n",
        "    return images, ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assigning the numpy array transformed 5111 training images plus the ids into the test_data variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images: 100%|██████████| 5111/5111 [00:03<00:00, 1589.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final data size (5111, 299, 299, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_data, ids = load_test_images('images/test/')\n",
        "\n",
        "# Save the ids to a pickle file\n",
        "with open('ids.pkl', 'wb') as f:\n",
        "    pickle.dump(ids, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function will extract the features taking the same models we've used before and return a variable concatenating all the 4 model features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(data, img_size=(299, 299, 3)):\n",
        "    \"\"\"\n",
        "    Extracts features from test data using multiple pre-trained models \n",
        "    and concatenate them\n",
        "    Parameters:\n",
        "        data: numpy array, the input data we need to extract features from\n",
        "        img_size: tuple, size to which the images\n",
        "        should be resized (width, height, channels)\n",
        "    Returns:\n",
        "        a numpy array containing concatenated features from multiple models\n",
        "    \"\"\"\n",
        "    # Extract features using InceptionV3\n",
        "    inception_features = get_features(InceptionV3, inception_preprocessor, img_size, data)\n",
        "\n",
        "    # Extract features using Xception\n",
        "    xception_features = get_features(Xception, xception_preprocessor, img_size, data)\n",
        "\n",
        "    # Extract features using NASNetLarge\n",
        "    nasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, data)\n",
        "\n",
        "    # Extract features using InceptionResNetV2\n",
        "    inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, data)\n",
        "\n",
        "    # Concatenate all extracted features along the last axis\n",
        "    final_features = np.concatenate(\n",
        "        [inception_features, xception_features, nasnet_features, inc_resnet_features],\n",
        "        axis=-1\n",
        "    )\n",
        "\n",
        "    # Free RAM\n",
        "    del inception_features, xception_features, nasnet_features, inc_resnet_features\n",
        "    gc.collect()\n",
        "\n",
        "    return final_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assigning the extracted features from test_data (the dog pictures inside train/) into the test_features variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 491ms/step\n",
            "Feature maps shape:  (5111, 2048)\n",
            "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 963ms/step\n",
            "Feature maps shape:  (5111, 2048)\n",
            "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 2s/step\n",
            "Feature maps shape:  (5111, 4032)\n",
            "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 1s/step\n",
            "Feature maps shape:  (5111, 1536)\n"
          ]
        }
      ],
      "source": [
        "test_features = extract_features(test_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
